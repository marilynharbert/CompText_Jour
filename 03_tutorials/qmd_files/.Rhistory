knitr::opts_chunk$set(echo = TRUE)
#KEY
md_race <- read_csv("lab_03.csv")
library(tidyverse)
library(janitor)
#KEY
md_race <- read_csv("lab_03.csv")
md_race <- read_csv("/Users/robwells/Code/data_journalism_class/04_labs/lab_03/lab_03.csv")
md_race %>%
select(place,x2020_hispanic,x2010_hispanic,x2020_total) %>%
slice_max(x2020_hispanic,n=15)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_04")
# Turn off scientific notation
options(scipen=999)
# Load the tidyverse here
# Load janitor here
#KEY
library(tidyverse)
library(janitor)
# Write code to load the Maryland race by city, place for 2010 - 2020 and call it md_race.
# The data is called lab_04.csv, and is in the same folder as lab_04.qmd (this data notebook)
#KEY
library(here)
here::here("/Code/data_journalism_interactive_textbook/04_labs/lab_04")
md_race <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_04/lab_04.csv"))
# Write your code in this codeblock.
#KEY
top5_hispanic_pct <- md_race %>%
select(place, x2020_total, x2020_hispanic) %>%
mutate(pct_hispanic = (x2020_hispanic/x2020_total)) %>%
slice_max(pct_hispanic, n =5)
top5_hispanic_pct
#write your code here
#KEY
pct_black <- md_race %>%
select(place, x2020_black, x2020_total, x2010_black, x2010_total) %>%
filter(x2010_total > 20000) %>%
mutate(pct_black_2020 = (x2020_black/x2020_total)) %>%
mutate(pct_black_2010 = (x2010_black/x2010_total)) %>%
select(place, pct_black_2020, pct_black_2010, x2020_black, x2020_total, x2010_black, x2010_total) %>%
slice_max(pct_black_2020, n = 10)
pct_black
# KEY
hisp_growth <- md_race %>%
select(place, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
filter(x2020_total > 10000) %>%
mutate(hispanic_growth = ((x2020_hispanic-x2010_hispanic)/x2010_hispanic)*100) %>%
mutate(total_growth = ((x2020_total-x2010_total)/x2010_total)*100) %>%
select(place,hispanic_growth, total_growth, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
slice_max(hispanic_growth, n = 15)
hisp_growth
hisp_growth <- md_race %>%
select(place, x2020_hispanic, x2020_total, x2010_hispanic, x2010_total) %>%
filter(x2020_total > 10000) %>%
mutate(hisp_change = (x2020_hispanic - x2010_hispanic)/x2010_hispanic * 100,
total_change = (x2020_total - x2010_total)/x2010_total * 100) %>%
arrange(desc(hisp_change))
View(hisp_growth)
library(formattable)
#then calculate percent change for top 5 cities with highest Hispanic pops. and create a new table
top5_hispanic <- md_race %>%
select(place, x2020_hispanic, x2020_total) %>%
mutate(pct_total_hispanic = percent(x2020_hispanic/x2020_total)) %>%
slice_max(pct_total_hispanic, n = 5)
View(top5_hispanic)
top5_hispanic <- md_race %>%
select(place,x2020_hispanic,x2020_total) %>%
mutate(ratio_h=((x2020_hispanic/x2020_total)*100)) %>%
arrange(desc(ratio_h)) %>%
slice_head(n = 5)
View(top5_hispanic)
baltcity_income<- read_csv("assets/data/baltcity_income_clean.csv") %>%
as.data.frame()
baltcity_income<- read_csv("/Users/robwells/Library/CloudStorage/GoogleDrive-robwells@umd.edu/My Drive/Data Spring 2024/Storage Spring 2024 Data/data_journalism_interactive_textbook/04_labs/lab_05/pre_lab_05/baltcity_income_clean.csv") %>%
as.data.frame()
summary(baltcity_income$x2020)
baltcity_income<- read_csv("/Users/robwells/Library/CloudStorage/GoogleDrive-robwells@umd.edu/My Drive/Data Spring 2024/Storage Spring 2024 Data/data_journalism_interactive_textbook/04_labs/lab_05/pre_lab_05/baltcity_income_clean.csv") %>%
as.data.frame()
summary(baltcity_income$x2020)
top <- baltcity_income %>%
select(Census, x2020) %>%
filter(x2020 > 56311) %>%
count()
#There were 97 census tracts above the citywide median income of $49875
bottom <- baltcity_income %>%
select(Census, x2020) %>%
filter(x2020 < 56311) %>%
count()
View(top)
View(bottom)
answer <- (bottom/200)
answer
View(answer)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_05")
# Turn off scientific notation
options(scipen=999)
#KEY
library(tidyverse)
library(janitor)
here::here("/Code/data_journalism_class/04_labs/lab_05")
us_death <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/CDC_Life_Census_Tract_2010_2015.csv"))
us_death <- janitor::clean_names(us_death)
nrow(us_death)
#73121
names(us_death)
#
md_death <- us_death %>%
filter(state == "Maryland")
nrow(md_death)
#1407
balt_death <- md_death %>%
filter(county == "Baltimore city, MD")
nrow(balt_death)
#200
#KEY
balt_death2 <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/balt_death_census.csv"))
summary(balt_death2$life_expectancy, na.m=TRUE)
#Show in New Window
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
# 62.60   69.58   72.70   73.04   76.03   87.30      20
balt_death2 %>%
select(neighborhood, life_expectancy) %>%
filter(life_expectancy <= 69.58) %>%
arrange(life_expectancy)
#KEY
balt_death2 <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/balt_death_census.csv"))
summary(balt_death2$life_expectancy, na.m=TRUE)
#Show in New Window
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
# 62.60   69.58   72.70   73.04   76.03   87.30      20
balt_death2 %>%
select(neighborhood, life_expectancy) %>%
filter(life_expectancy <= 69.58) %>%
arrange(life_expectancy)
#KEY
balt_death <- balt_death %>%
mutate(
above_below_avg = case_when(
life_expectancy >= '72.7' ~ "Above",
life_expectancy <= '72.7' ~ "Below"
)
balt_death %>%
count(above_below_avg)
knitr::opts_chunk$set(echo = TRUE)
here::here("/Code/data_journalism_class/04_labs/lab_05/pre_lab_05/")
mdcities <- read_csv(here::here("~/Code/data_journalism_class/04_labs/lab_05/pre_lab_05/city_md_income.csv")) %>%
as.data.frame()
mdcities <- mdcities %>%
mutate(income_diff = (median_inc_2020-median_inc_2010)) %>%
mutate(income_pct_chg = round((median_inc_2020-median_inc_2010)/median_inc_2010*100,2))
View(mdcities)
summary(mdcities)
summary(mdcities$median_inc_2020)
lowest <- mdcities %>%
mutate(
category = case_when(
median_inc_2020 <= `63327` ~ "lowest",
median_inc_2020 >= `63327` ~ "above"
)
lowest <- mdcities %>%
mutate(
category = case_when(
median_inc_2020 <= "63327" ~ "lowest",
median_inc_2020 >= "63327" ~ "above"
)
View(lowest)
library(quarto)
quarto::quarto_render()
setwd("~/Code/data_journalism_class/03_tutorials/qmd_files")
library(quarto)
quarto::quarto_render()
library(tidyverse)
###
# Total population for each Maryland county
# County identified by GEOID (a 5-digit code), not name
###
maryland_county_population <- read_rds("assets/data/maryland_county_population.rds")
###
# A lookup table that shows the name of each Maryland county, paired with GEOID
###
maryland_county_lookup_table <- read_rds("assets/data/maryland_county_lookup_table.rds")
###
# Total population for each Maryland county, EXCEPT for Prince George's County
# County identified by GEOID (a 5-digit code), not name
###
maryland_county_population_no_pg <- read_rds("assets/data/maryland_county_population_no_pg.rds")
###
# Display the tables
###
maryland_county_population
maryland_county_lookup_table
maryland_county_population_no_pg
updated_maryland_county_population <- maryland_county_lookup_table %>%
inner_join(maryland_county_population, by="geoid")
updated_maryland_county_population
updated_maryland_county_population_no_pg <- maryland_county_lookup_table %>%
inner_join(maryland_county_population_no_pg, by="geoid")
updated_maryland_county_population_no_pg
if (knitr::is_html_output())
knitr::include_graphics("assets/inner-join.gif")
# ![inner join](assets/inner-join.gif){width="100%"}
updated_maryland_county_population_no_pg <- maryland_county_lookup_table %>%
left_join(maryland_county_population_no_pg, by="geoid")
updated_maryland_county_population_no_pg
View(maryland_county_population)
View(maryland_county_lookup_table)
View(maryland_county_population)
maryland_tracts <- rio::import("maryland_tracts.xls")
md_counties_goeids <- rio::import("md_counties_goeids.txt")
md_counties_geoids <- rio::import("md_counties_geoids.txt")
names(md_counties_geoids)
names(maryland_tracts)
View(maryland_tracts)
md_smith_data <- maryland_tracts %>%
inner_join(md_counties_geoids, by=("cty"="GEOID"))
md_smith_data <- maryland_tracts %>%
inner_join(md_counties_geoids, by=c("cty"="GEOID"))
View(md_smith_data)
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
summarize(average = mean(census_response_rate2020)) %>%
arrange(desc(average))
View(census)
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
summarize(average = mean(census_response_rate2020, na.rm = TRUE)) %>%
arrange(desc(average))
census <- md_smith_data %>%
select(NAME, census_response_rate2020) %>%
group_by(NAME) %>%
summarize(average = mean(census_response_rate2020, na.rm = TRUE)) %>%
arrange(desc(average))
View(census)
quarto::quarto_render(input = "index.qmd", output_file = "index.html")
library(tidyverse)
library(textdata)
library(tidytext)
library(quanteda)
library(rio)
#import df created from sequence below
black <- read.csv("../data/black_press_extracted_text_june_22_2024.csv")
getwd()
black <- read.csv("../CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
black <- read.csv("~/Code/CompText_Jour/data")
black <- read.csv("~/Code/CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
#import df created from sequence below
black <- read.csv("~/Code/CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
all_text <- str_replace_all(black$sentence, "- ", "")
text_df <- tibble(all_text,)
# unnest includes lower, punct removal
text_tokenized <- text_df %>%
unnest_tokens(word,all_text)
text_tokenized
#Remove stopwords
data(stop_words)
text_tokenized<- text_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
#NOT SURE IF THIS LINE SHOULD REMAIN
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# fix the script so it doesn't pick up these file names, numbers
# forcibly removing for now
# Word Count
text_word_ct <- text_tokenized %>%
count(word, sort=TRUE)
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
nrc_sentiments %>% count(sentiment)
#sentiment & count
# anger	1246
# anticipation	837
# disgust	1056
# fear	1474
# joy	687
# negative	3318
# positive	2308
# sadness	1187
# surprise	532
# trust	1230
nrc_sentiments %>%
group_by(word) %>%
count() %>%
arrange(desc(n)) %>%
distinct()
nrc_sentiments %>%
group_by(word) %>%
count() %>%
arrange(desc(n)) %>%
distinct()
sentiments_all <- text_tokenized %>%
inner_join(nrc_sentiments)
#this dictionary assigns different values to the same word. negro is negative, sadness whereas lynch is anger, disgust, fear, negative and sadness.
x <- sentiments_all %>%
group_by(word) %>%
count(sentiment)
View(x)
sentiments_all <- text_tokenized %>%
inner_join(nrc_sentiments) %>%
count(sentiment, sort = TRUE) %>%
mutate(pct_total =round(n/sum(n), digits=2))
sentiments_all
library(ggplot2)
afinn_plot <- ggplot(sentiments_all,aes(x = sentiment, y = n,fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "Total Sentiment in Black Press Lynching News Coverage",
subtitle = " ",
caption = "NRC Sentiment analysis. Graphic by Rob Wells, 8-25-2024",
y="Score",
x="total sentiment score")
afinn_plot + scico::scale_fill_scico(palette = "vik")
# ggsave("Figure5_afinn_sentiment_jan2.png",device = "png",width=9,height=6, dpi=800)
# Anger
nrc_anger <- nrc_sentiments %>%
filter(sentiment == "anger")
lynching_anger <- text_tokenized %>%
inner_join(nrc_anger) %>%
count(word, sort = TRUE)
lynching_anger
# Anticipation
# results / themes not as clear as anger
nrc_anticipation <- nrc_sentiments %>%
filter(sentiment == "anticipation")
lynching_anticipation <- lynching_tokenized %>%
inner_join(nrc_anticipation) %>%
count(word, sort = TRUE)
# Anticipation
# results / themes not as clear as anger
nrc_anticipation <- nrc_sentiments %>%
filter(sentiment == "anticipation")
lynching_anticipation <- text_tokenized %>%
inner_join(nrc_anticipation) %>%
count(word, sort = TRUE)
lynching_anticipation
# Fear
# see a reflection of the basic word count in these results
nrc_fear <- nrc_sentiments %>%
filter(sentiment == "fear")
lynching_fear <- text_tokenized %>%
inner_join(nrc_fear) %>%
count(word, sort = TRUE)
lynching_fear
# Disgust
# see a reflection of the basic word count in these results
nrc_disgust <- nrc_sentiments %>%
filter(sentiment == "disgust")
lynching_disgust <- text_tokenized %>%
inner_join(nrc_disgust) %>%
count(word, sort = TRUE)
lynching_disgust
text_500 <- text_word_ct %>%
filter(n >= 29)
View(text_500)
custom_dictionary <- text_500 %>%
inner_join(nrc_sentiments)
View(custom_dictionary)
knitr::opts_chunk$set(echo = TRUE)
system("brew install tesseract")
system("brew install xpdf")
system("xcode-select --install")
system("brew install libtiff")
system("brew install ghostscript")
system("brew install imagemagick")
system("pdftotext /Users/robwells/Code/misc_notes/notes/Manafort_filing.pdf name-of-my-text-file.txt")
# For tabular data
system("pdftotext -table /Users/robwells/Code/misc_notes/notes/07012018-report-final.pdf tabular-test1.txt")
library(fs)
# Set paths
pdf_folder <- "/Users/robwells/Code/misc_notes/pdfs"
extracted_folder <- "/Users/robwells/Code/misc_notes/extracted"
# Create the extracted folder if it doesn't exist
if (!dir_exists(extracted_folder)) {
dir_create(extracted_folder)
}
# Get list of PDF files
pdf_files <- dir_ls(pdf_folder, glob = "*.pdf")
# Process each PDF file
for (pdf_file in pdf_files) {
output_file <- path(extracted_folder, path_ext_set(path_file(pdf_file), "txt"))
system2("pdftotext", args = c(pdf_file, output_file))
cat("Text extracted from", path_file(pdf_file), "and saved to", path_file(output_file), "\n")
}
# Install tesseract if not already installed
system("brew install tesseract")
# Convert PNG to searchable PDF
system("tesseract /Users/robwells/Code/misc_notes/pdfs/'a lynching in ohio.png' out.pdf")
# Convert the searchable PDF to text
system("pdftotext out.pdf out.txt")
knitr::include_graphics(rep("images/md_voters.png"))
knitr::include_graphics(rep("images/md_voters2.png"))
voters_by_county <- read_csv("data/tabula-Eligible Active Voters by County - PG20.csv")
voters_by_county <- read_csv("images/tabula-Eligible Active Voters by County - PG20.csv")
library(tidyverse)
voters_by_county <- read_csv("images/tabula-Eligible Active Voters by County - PG20.csv")
voters_by_county
knitr::include_graphics(rep("images/ppp_1.png"))
knitr::include_graphics(rep("images/ppp_2.png"))
knitr::include_graphics(rep("images/ppp_3.png"))
lender_types <- read_csv("images/tabula-PPP_Report_Public_210531-508.csv")
lender_types
lender_types <- read_csv("data/tabula-PPP_Report_Public_210531-508.csv", skip=1, col_names=c("type", "count", "approved", "net_dollars"))
lender_types <- read_csv("images/tabula-PPP_Report_Public_210531-508.csv", skip=1, col_names=c("type", "count", "approved", "net_dollars"))
lender_types <- lender_types %>% mutate(net_dollars=as.numeric(parse_number(net_dollars)))
lender_types
library(tidyverse)
library(janitor)
library(lubridate)
library(kableExtra)
milw <- rio::import("../data/sta_wi_milwaukee_2019_2020.csv")
milw <- janitor::clean_names(milw)
glimpse(milw)
milw$defendant_address2 <- milw$defendant_address
x <- separate(data = milw, col = defendant_address, into = c("address", "city", "state_zip"), sep = ", ", extra = "merge", fill = "right")
x %>%
group_by(city) %>%
count(city) %>%
arrange(desc(n))
glimpse(milw)
#Process dates
milw$date <- ymd(milw$file_date)
milw <- milw %>%
mutate(yearmon = format(date, "%Y-%m"))
glimpse(milw)
milw_bak <- milw
milw <- milw %>%
filter(file_date <= as.Date("2020-07-31")) %>%
distinct()
z <- milw %>%
group_by(yearmon) %>%
count(yearmon)
z
#write.csv(z, "miltotal.8.21.2020.csv")
summary(z$n)
sum(z$n)
ggplot(z, aes(x=yearmon, y=n, fill=yearmon)) +
geom_col() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(title="Milwaukee City-County Eviction Filings Per Month Jan. 2019-July 2020",y="Evictions", x= "",
caption = "Graphic by Rob Wells. 8-21-2020", subtitle = "Source: Wisconsin Circuit Court records")+
theme(legend.position="none")
#ggsave("Milw_Evict_8_21_2020.png",device = "png",width=9,height=6, dpi=500)
p <- milw
p$plaintiff_one <- str_trim(p$plaintiff)
p$defendant_one <- str_trim(p$defendant)
p$plaintiff_one <- gsub("[[:punct:]]", "", p$plaintiff_one)
p$defendant_one <- gsub("[[:punct:]]", "", p$defendant_one)
head(p)
p$plaintiff_one <- gsub("[0-9]", "", p$plaintiff_one)
head(p)
#Build a simple summary table
plaintiff1 <- p %>%
select(plaintiff_one, defendant_one, date) %>%
group_by(plaintiff_one) %>%
count(plaintiff_one) %>%
ungroup() %>%
arrange(desc(n))
#write.csv(plaintiff1, "milplaintiff.7.6.2020.csv")
plaintiff1
#quick fact check on totals: 19,420 checks out
sum(plaintiff1$n)
summary(plaintiff1)
x <- p %>%
filter(date > '2020-03-27')
#write.csv(x, "mil_all_march27forward.csv")
moratorium <- p %>%
filter(date > '2020-03-27') %>%
select(plaintiff_one, defendant_one, date) %>%
group_by(plaintiff_one) %>%
count(plaintiff_one) %>%
ungroup() %>%
arrange(desc(n))
#write.csv(moratorium, "milplaintiff.8.4.2020.csv")
sum(moratorium$n)
top <- p %>%
filter(date > '2020-03-27') %>%
select(plaintiff_one, yearmon) %>%
group_by(plaintiff_one, yearmon) %>%
count(plaintiff_one) %>%
filter(n > 5) %>%
ungroup() %>%
arrange(yearmon) %>%
arrange(desc(n))
#write.csv(top, "mil_evictors_mo_8_4_2020.csv")
head(top)
summary(moratorium)
p2 <- p
p2$plaintiff_fixed <- p2$plaintiff_one
glimpse(p2)
quarto::quarto_render(input = "r_writing-data.qmd", output_file = "r_writing-data.html")
quarto::quarto_render(input = "r-writing-data.qmd", output_file = "r-writing-data.html")
quarto::quarto_render()
