---
title: "NRC Sentiment_Analysis"
author: "Rob Wells"
date: "2024-8-25"
output: html_document
---

# Jour389/689 Fall 2024

Follow this script and use this dataset instead:
https://github.com/wellsdata/CompText_Jour/raw/main/data/black_press_extracted_text_june_22_2024.csv

load the following libraries: tidyverse, textdata, tidytext, quanteda, rio

```{r}
install.packages("textdata")
library(tidyverse)
library(textdata)
library(tidytext)
library(quanteda)
library(rio)


```


#import "articles_oct_19.csv" as a dataframe

```{r}
#import df created from sequence below

<<<<<<< HEAD
lynch <- read.csv("~/Code/CompText_Jour/data/black_press_extracted_text_june_22_2024.csv")
=======
```
>>>>>>> 85c67fcf0f2762dc4d91b5a269c3c0178fe0a7f3

#Tokenize sentence into a df, remove stopwords


```{r}
```


<<<<<<< HEAD
# Word Countyes
=======
# Count the words in descending order
```{r}
# Word Count
>>>>>>> 85c67fcf0f2762dc4d91b5a269c3c0178fe0a7f3

text_word_ct <- text_tokenized %>%
  count(word, sort=TRUE)
```

# NRC Sentiment

NRC Lexicon on Whole Corpus
"The nrc lexicon categorizes words in a binary fashion (“yes”/“no”) into categories of positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust."
```{r}
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
```

#Count the NRC sentiments
```{r}

```

### Join the NRC Sentiments with the tokenized data


```{r}

sentiments_all <- text_tokenized %>%
  inner_join(nrc_sentiments) 

<<<<<<< HEAD

dropped <- text_tokenized %>%
  mutate(token = "text_token") %>%
  anti_join(nrc_sentiments) %>%
  filter(token == "text_token")

dropped <- dropped %>%
  select(word) %>%
  group_by(word) %>%
  count()



#this dictionary assigns different values to the same word. negro is negative, sadness whereas lynch is anger, disgust, fear, negative and sadness.

x <- sentiments_all %>% 
  group_by(word) %>% 
    count(sentiment)

=======
>>>>>>> 85c67fcf0f2762dc4d91b5a269c3c0178fe0a7f3
```

### Count Overall Sentiment with NRC

```{r}

```

<<<<<<< HEAD


## Figure 5: Sentiment chart
```{r}
library(ggplot2)


afinn_plot <- ggplot(sentiments_all,aes(x = sentiment, y = n,fill = n)) +
  geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "Total Sentiment in Black Press Lynching News Coverage",
       subtitle = " ",
       caption = "NRC Sentiment analysis. Graphic by Rob Wells, 8-25-2024",
       y="Score",
       x="total sentiment score")

install.packages("scico")
library(scico)

afinn_plot + scico::scale_fill_scico(palette = "vik")

# ggsave("Figure5_afinn_sentiment_jan2.png",device = "png",width=9,height=6, dpi=800)


```
=======
## Use ggplot to chart Sentiments with the tokenized data
>>>>>>> 85c67fcf0f2762dc4d91b5a269c3c0178fe0a7f3

```{r}

```



# Create a new dataframe just with the NRC "anger" sentiment
```{r}


```

<<<<<<< HEAD

Overall, negative sentiment was 70% of the Southern newspaper coverage but just 69% of the Northern newspaper coverage.

```{r}
# modify for new lynch decade data set
all_text <- str_replace_all(lynch$sentence, "- ", "")
text_df <- tibble(all_text,)

# unnest includes lower, punct removal

text_tokenized <- text_df %>%
  unnest_tokens(word,all_text)

text_tokenized

#Remove stopwords

data(stop_words)

text_tokenized<- text_tokenized %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(word != "temp_file") %>%
  #NOT SURE IF THIS LINE SHOULD REMAIN
  filter(word != "stories_corpus") %>%
  filter(!grepl('[0-9]', word))

# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")

nrc_sentiments %>% count(sentiment)

#sentiment & count
# anger	1246			
# anticipation	837			
# disgust	1056			
# fear	1474			
# joy	687			
# negative	3318			
# positive	2308			
# sadness	1187			
# surprise	532			
# trust	1230	

nrc_sentiments %>% 
  group_by(word) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  distinct()

sentiments_south <- sentiments_all %>% 
  filter(region == "South") %>%
  rename(south_n = n, south_pct = pct_total)

sentiments_north <- sentiments_all %>% 
  filter(region == "North") %>%
  rename(north_n = n, north_pct = pct_total)

sentiments_border <- sentiments_all %>% 
  filter(region == "Border") %>%
  rename(border_n = n, border_pct = pct_total)

sentiments_misc <- sentiments_all %>% 
  filter(region == "Misc") %>%
  rename(misc_n = n, misc_pct = pct_total)



sent_regions <- sentiments_south %>% 
  inner_join(sentiments_north) %>% 
  inner_join(sentiments_border) %>% 
  inner_join(sentiments_misc)

#write.csv(sent_regions, "sent_regions_jan6.csv")
```



=======
>>>>>>> 85c67fcf0f2762dc4d91b5a269c3c0178fe0a7f3
