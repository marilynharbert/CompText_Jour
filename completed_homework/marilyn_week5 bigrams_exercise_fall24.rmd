---
title: "Bigrams Exercise Sept 24"
author: "Marilyn Harbert"
date: '2024-09-24'
output: html_document
---

# Jour 389/689 Fall 2024:


```{r}
#load tidyverse, tidytext, rio and quanteda libraries

library(quanteda)
library(tidyverse)
library(tidytext)
library(rio)
```

```{r}
#Import dataframe 

lynch <- read_csv("../data/articles_oct_19.csv")

```


# Create a new dataframe that filters articles for 1900 to 1910

```{r}

lynch1900s <- lynch %>%
  filter(year > 1899 & year < 1911)

#rsw comment: for precision:
lynch1910 <-  lynch %>% 
  filter(year >= 1900 & year <= 1910)

```


# Count the number of distinct articles in 1900 dataframe
```{r}

n_distinct(lynch1900s$article_id)
#rsw comment: good solution but n_distinct should have been on filename
n_distinct(lynch1900s$filename)

#my flabbier version. but nice one with n_distinct!
lynch1910 %>% 
  select(filename) %>% 
 distinct(filename, .keep_all = TRUE) %>% 
  count(filename) %>% 
  summarize(total =sum(n)) 
#There are 1,732 distinct articles in the dataset for the 1900-1910 

```

# Count the number of newspaper_states in the 1900 corpus
```{r}

n_distinct(lynch1900s$newspaper_state)
#rsw comment: I was looking for the individual states:
states1900 <- lynch1910 %>% 
  select(newspaper_state, filename) %>% 
  distinct(filename, .keep_all = TRUE) %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

#and now provide code to list the top five states
states1900 %>% 
  select(newspaper_state, n) %>% 
slice_max(n, n=10)

```

# Tokenize the 1900 lynching stories

```{r}
lynch_1900s_tokenized <- lynch1900s %>%
  unnest_tokens(word,sentence)


```


#Remove stopwords
The tidytext package includes the stop_words dataset.It contains, as of this writing, 1,149 words that data scientists and linguistic nerds felt could be removed from sentences because they don't add meaning. Filtering out these words can help focus on the more meaningful content, making it easier to uncover trends, themes, and key information in large amounts of text. Obviously, we have different priorities and we may or may not want to use stop_words or we have want to provide a customized list of stop words.

The stop_words list is derived from three separate lists, or lexicons: SMART (571 words), onix (404 words), and snowball (174 words)

The ONIX lexicon comes from the Open Information Exchange and is often used in text mining and natural language processing. 

The Snowball lexicon is part of a broader project that has algorithms that simplify words in different languages by reducing them to their root form. It's best known for the Porter stemming algorithm, which, for example, changes "running" to "run." 

Lastly, the SMART lexicon is a set of common words, like "and," "the," and "is," and it comes from the SMART Information Retrieval System, created at Cornell University in the 1960s.

```{r}
data(stop_words)

test <- stop_words %>% 
  as.data.frame()

head(test)
```
# Strip out stop words

```{r}

lynch_1900s_tokenized <- lynch_1900s_tokenized %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(word != "temp_file") %>%
  filter(word != "stories_corpus") %>%
  filter(!grepl('[0-9]', word))

# Word Count

lynch_word_ct <- lynch_1900s_tokenized %>%
  count(word, sort=TRUE)

head(lynch_word_ct)


```

# Bigrams
## We are now creating two word phrases but before the stop words are taken out

```{r}


lynch_bigrams <- lynch1900s %>%
  unnest_tokens(bigram, sentence, token="ngrams", n=2)
#rsw comment - missing an intermediate step here:
#this creates a single dataframe just with the news content.
stories <- str_replace_all(lynch1910$sentence, "- ", "")
stories_df <- tibble(stories,)

#this part is ok
lynch_bigrams_separated <- lynch_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

```

# Create a new dataframe with counts of the bigrams
```{r}

count_lynch_bigrams <- lynch_bigrams %>%
  count(bigram, sort=TRUE)

```

## Now filter the counts 
```{r}

lynch_bigrams_filtered <- lynch_bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

lynch_bigram_cts2 <- lynch_bigrams_filtered %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(!is.na(word1))

lynch_bigram_cts2
```

# Add a "1900" decade column

Hint: use mutate
 
```{r}

lynch_bigrams_filtered <- lynch_bigrams_filtered %>%
  mutate(decade_1900 = (year >1899 & year <1910))

```


# YOUR TURN

Create one dataframe with black press articles
Create a second dataframe without black press articles
Produce the top 20 bigrams for the black press and non-black press coverage
Compare and discuss!

 
```{r}
#rsw comment - this results in a significant undercount. I would up just remaking two separate dataframes from scratch and comparing them. See my version: https://github.com/wellsdata/CompText_Jour/blob/main/exercises/week5%20KEY%20bigrams_exercise_fall24.Rmd

lynch_black_press_articles <- lynch_bigrams_filtered %>%
  filter(black_press == "Y") 

lynch_non_black_press_articles <- lynch_bigrams_filtered %>%
  filter(is.na(black_press)) 


```

Produce the top 20 bigrams for the black press and non-black press coverage
 
```{r}

top_20_bigrams_black_press <- lynch_black_press_articles %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(!is.na(word1)) %>%
  head(20)

top_20_bigrams_nonblack_press <- lynch_non_black_press_articles %>%
  count(word1, word2, sort = TRUE) %>% 
  filter(!is.na(word1)) %>%
  head(20)

top_20_bigrams_black_press
top_20_bigrams_nonblack_press

```


Compare and discuss!

Within this dataset, it seems that there were ##rsw comement - incorrect ## only 10 articles within the 1900-1910 range, so it is hard to generalize, but for the articles present, in both the cases of black and non-black press articles, some variation of "lynch" was present in the most common bigram. In the black press articles the bigrams such as "officers found" or "july 16" and "county officers" suggests that articles in this data set written by members of the black press may have been more focused on reporting details of lynching cases and stories, whereas the prevelancy of "supreme court" and "mob violence" suggest that maybe white press articles are mroe focused on reporting bigger picture elements of these stories. 



